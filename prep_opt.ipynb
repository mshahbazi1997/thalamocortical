{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "np.set_printoptions(linewidth=200)\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "\n",
    "from time import time\n",
    "\n",
    "from myutils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'naming' from 'tensorflow.python.autograph.core' (/Users/sean/miniconda3/envs/rocky/lib/python3.8/site-packages/tensorflow/python/autograph/core/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4d33ffc4fa11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_probability\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mctrnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCTRNNCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPlotEachBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# tf.keras.backend.set_floatx('float32')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rocky/lib/python3.8/site-packages/tensorflow_probability/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# from tensorflow_probability.google import staging  # DisableOnExport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# pylint: enable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rocky/lib/python3.8/site-packages/tensorflow_probability/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdebugging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rocky/lib/python3.8/site-packages/tensorflow_probability/python/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauto_batching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0medward2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rocky/lib/python3.8/site-packages/tensorflow_probability/python/experimental/auto_batching/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_batching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallocation_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_batching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdsl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_batching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrontend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_batching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minstructions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_batching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mliveness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rocky/lib/python3.8/site-packages/tensorflow_probability/python/experimental/auto_batching/frontend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreturn_statements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnaming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyct\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyct\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'naming' from 'tensorflow.python.autograph.core' (/Users/sean/miniconda3/envs/rocky/lib/python3.8/site-packages/tensorflow/python/autograph/core/__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from ctrnn import CTRNNCell, PlotEachBatch\n",
    "\n",
    "# tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0-dev20200722'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _real_with_test(x, name='x', tol=1e-6):\n",
    "    imag_norm = tf.linalg.norm(tf.reshape(tf.math.imag(x), -1))\n",
    "    tot_norm = tf.cast(tf.linalg.norm(tf.reshape(x, -1)), tf.float64)\n",
    "    if imag_norm / tot_norm > tol:\n",
    "        tf.print(f'||{name}.imag||/||{name}|| = {imag_norm / tot_norm}')\n",
    "    return tf.math.real(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 25\n",
    "act = tf.tanh\n",
    "g = 1.5\n",
    "dt = 0.001\n",
    "tau = 0.01\n",
    "sigma = 0.001\n",
    "alpha = 1.0\n",
    "classes = 2\n",
    "\n",
    "dur = 1.0\n",
    "pos1 = 0.35\n",
    "pos2 = 0.65\n",
    "width = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tau = dt / tau\n",
    "\n",
    "T = round(dur / dt)\n",
    "t = np.arange(T)\n",
    "\n",
    "f = np.stack([\n",
    "    np.exp(-0.5 * (t - pos1 * T)**2 / (width * T)**2) + np.exp(-0.5 * (t - pos2 * T)**2 / (width * T)**2),\n",
    "    1 - np.abs((t * dt * 4 - 1) % 4 - 2)\n",
    "    ])\n",
    "assert len(f) == classes, f'{classes} target functions needed, but only {len(f)} given'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "targets = []\n",
    "for i in range(500):\n",
    "    inputs.append(np.ones(T, dtype=int) * (i % classes))\n",
    "    targets.append(f[i % classes])\n",
    "inputs = get_one_hot(np.stack(inputs), classes)\n",
    "targets = np.stack(targets)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c8c6c7a63a4f8dbabb556e750581d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "a = plt.axes()\n",
    "for y in f:\n",
    "    a.plot(t * dt, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97a45b4e6b247518cedba57e0c4d7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(-1.0999791907454364,\n",
       " 1.099999009083116,\n",
       " -1.3312458901902486,\n",
       " 1.3312458901902486)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.seed(2)\n",
    "A = npr.randn(N, N) / np.sqrt(N)\n",
    "d, v = np.linalg.eig(A)\n",
    "plt.figure()\n",
    "theta = np.linspace(0, 2 * np.pi, 500)\n",
    "plt.plot(np.cos(theta), np.sin(theta), 'k')\n",
    "plt.plot(d.real, d.imag, '.')\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_f(U, V, A, w, tau, beta, eigf=tf.linalg.eig):\n",
    "    N = A.shape[0]\n",
    "    J = A + U @ V\n",
    "    d, r = eigf(J)\n",
    "    L = tf.linalg.inv(tf.linalg.adjoint(r) @ r)\n",
    "    g = (d - 1) / tau\n",
    "    G1 = -1 / (g[:, None] + tf.math.conj(g))\n",
    "    G2 = (g[:, None] * tf.math.conj(g)) * G1\n",
    "    wR = tf.linalg.matvec(r, tf.cast(w, tf.complex128), transpose_a=True) \n",
    "    return tf.math.real(tf.reduce_sum((r @ (L * G1)) * tf.math.conj(r)) / N + beta * tf.reduce_sum(wR * tf.linalg.matvec(L * G2, tf.math.conj(wR))))\n",
    "\n",
    "def _reciprocal(x, ep=1e-20):\n",
    "    return x / (x * x + ep)\n",
    "\n",
    "@tf.custom_gradient\n",
    "def myeig(A):\n",
    "    e, v = tf.linalg.eig(A)\n",
    "    def grad(grad_e, grad_v):\n",
    "        f = _reciprocal(e[..., None, :] - e[..., None])\n",
    "        f = tf.linalg.set_diag(f, tf.zeros_like(e))\n",
    "        f = tf.math.conj(f)\n",
    "        vt = tf.linalg.adjoint(v)\n",
    "        vgv = vt @ grad_v\n",
    "        diag_grad_part = tf.cast(tf.math.real(tf.linalg.diag_part(vgv)), vgv.dtype)\n",
    "        mid = tf.linalg.diag(grad_e) + f * (vgv - vt @ (v * diag_grad_part[..., None, :]))\n",
    "        grad_a = tf.linalg.solve(vt, mid @ vt)\n",
    "        return tf.cast(grad_a, A.dtype)\n",
    "    return (e, v), grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0241079330444336\n",
      "2.0073421001434326\n",
      "0.16692900657653809\n",
      "0.16349577903747559\n",
      "[(True, (True, 2.718997071556545e-15)), (True, (True, 1.256914119116992e-15))]\n",
      "[(True, (True, 2.250345406733898e-15)), (True, (True, 1.3108167355767136e-15))]\n",
      "[(True, (True, 7.521378025613445e-15)), (True, (True, 4.970108736850761e-15))]\n",
      "[(True, (True, 4.6834545820503055e-15)), (True, (True, 2.5860783855761247e-15))]\n",
      "[(True, (True, 4.0001986555501494e-14)), (True, (True, 2.2451181989856864e-14))]\n",
      "[(True, (True, 3.672746717114926e-13)), (True, (True, 1.2874293979415579e-13))]\n",
      "[(True, (True, 1.9123238042331307e-14)), (True, (True, 9.255436734099315e-15))]\n",
      "[(True, (True, 3.248692434161891e-14)), (True, (True, 1.5959244276483033e-14))]\n",
      "[(True, (True, 1.4527505343602214e-13)), (True, (True, 6.578688873667015e-14))]\n",
      "[(True, (True, 1.474282845272314e-14)), (True, (True, 9.268780660497847e-15))]\n"
     ]
    }
   ],
   "source": [
    "N = 25\n",
    "reps = 10\n",
    "npr.seed(0)\n",
    "\n",
    "Us = [tf.constant(npr.randn(n, (n * 2) // 5)) for n in np.linspace(N, N * reps, reps, dtype=int)]\n",
    "Vs = [tf.constant(npr.randn((n * 2) // 5, n)) for n in np.linspace(N, N * reps, reps, dtype=int)]\n",
    "As = [tf.constant(npr.randn(n, n) / np.sqrt(n)) for n in np.linspace(N, N * reps, reps, dtype=int)]\n",
    "ws = [tf.constant(npr.randn(n) / np.sqrt(n)) for n in np.linspace(N, N * reps, reps, dtype=int)]\n",
    "tau = 1\n",
    "beta = 0.5\n",
    "\n",
    "curtime = time()\n",
    "systapes = []\n",
    "syslosses = []\n",
    "for i in range(reps):    \n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch([Us[i], Vs[i]])\n",
    "        syslosses.append(loss_f(Us[i], Vs[i], As[i], ws[i], tau, beta))\n",
    "    systapes.append(tape)\n",
    "print(time() - curtime)\n",
    "\n",
    "curtime = time()\n",
    "mytapes = []\n",
    "mylosses = []\n",
    "for i in range(reps):    \n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch([Us[i], Vs[i]])\n",
    "        mylosses.append(loss_f(Us[i], Vs[i], As[i], ws[i], tau, beta, eigf=myeig))\n",
    "    mytapes.append(tape)\n",
    "print(time() - curtime)\n",
    "\n",
    "curtime = time()\n",
    "sysgrads = []\n",
    "for tape, loss, U, V in zip(systapes, syslosses, Us, Vs):\n",
    "    sysgrads.append(tape.gradient(loss, [U, V]))\n",
    "print(time() - curtime)\n",
    "\n",
    "curtime = time()\n",
    "mygrads = []\n",
    "for tape, loss, U, V in zip(mytapes, mylosses, Us, Vs):\n",
    "    mygrads.append(tape.gradient(loss, [U, V]))\n",
    "print(time() - curtime)\n",
    "\n",
    "for mygrad, sysgrad in zip(mygrads, sysgrads):\n",
    "    print([(np.allclose(a, b), isclose(a, b, 1e-6)) for a, b in zip(mygrad, sysgrad)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.random.normal((2, 3, 10, 10), dtype=tf.float64)\n",
    "d, r = tf.eig(A)\n",
    "\n",
    "b_dims = len(d.shape) - 1\n",
    "idx = tf.argsort(tf.math.real(d) + tf.math.imag(d), axis=-1)\n",
    "d_ = tf.gather(d, idx, batch_dims=b_dims)\n",
    "r_ = tf.gather(r, idx, batch_dims=b_dims)\n",
    "\n",
    "r_[0, 0], tf.stack([r[0, 0, i] for i in idx[0, 0]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(np.arange(6).reshape(2, 3))\n",
    "tf.gather_nd(a, [[[0, 0], [0, 2], [0, 1]], [[1, 0], [1, 2], [1, 1]]]), array_ops.matrix_transpose(array_ops.gather(array_ops.matrix_transpose(a), [0, 2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[[0, 0], [0, 2], [0, 1]], [[1, 0], [1, 2], [1, 1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(tf.cast(A[0, 0], tf.complex128), r_[0, 0] @ tf.linalg.diag(d_[0, 0]) @ tf.linalg.inv(r_[0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import array_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.complex(npr.randn(3, 3), npr.randn(3, 3))\n",
    "a, a + 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 7., -5.],\n",
       "        [10., -8.]]),\n",
       " array([[-8.8817842e-16,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.array(([1., 1.], [1., 2.]))\n",
    "r = r / np.linalg.norm(r, axis=0)\n",
    "d = np.array([2., -3.])\n",
    "a = np.linalg.solve(r.T, (r * d).T).T\n",
    "# a = a @ a.T\n",
    "d, r = np.linalg.eig(a)\n",
    "l = np.linalg.inv(r)\n",
    "a, a - (r * d) @ l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.82842712e+00, -1.41421356e+00,  1.11022302e-10, -1.07331262e-01],\n",
       "       [-2.23606798e+00,  2.23606798e+00,  0.00000000e+00,  5.36656228e-02]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep = 1e-6\n",
    "np.hstack((l, (np.linalg.eig(a + [[0, ep], [ep, 0]])[1] - np.linalg.eig(a)[1]) / ep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.85046229e-11, -3.79473373e-02],\n",
       "       [ 4.96506831e-11, -7.24899973e-09]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.T @ ((np.linalg.eig(a + [[0, ep], [ep, 0]])[1] - np.linalg.eig(a)[1]) / ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myeig(a):\n",
    "    d, r = np.linalg.eig(a)\n",
    "    idx = np.argsort(d)\n",
    "    d = d[idx]\n",
    "    r = r[:, idx]\n",
    "    r = r * np.exp(-np.angle(r[0]) * 1j)\n",
    "    return d, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-5.04977876e-01-2.87022106e-01j,  5.85491942e-01-3.14662586e-01j,  2.84134578e-01+3.29456960e-01j,  1.17878199e-02+2.22586186e-02j,  1.13282231e-02+1.79859714e-02j],\n",
       "        [ 5.85491942e-01+3.14662586e-01j, -5.04977876e-01+2.87022106e-01j,  2.84134578e-01-3.29456960e-01j,  1.13282231e-02-1.79859714e-02j,  1.17878199e-02-2.22586186e-02j],\n",
       "        [ 1.97208344e-01-4.37940471e-02j,  1.97208344e-01+4.37940471e-02j, -4.78530404e-01+1.63127580e-17j, -1.54219079e-02-7.60103118e-03j, -1.54219079e-02+7.60103118e-03j],\n",
       "        [-1.33534149e-02+4.73701169e-02j, -1.37565812e-02+3.91905175e-02j, -4.80654734e-02+5.40799402e-02j, -5.59473320e-04+5.56933999e-04j, -4.44972926e-03-1.22506191e-03j],\n",
       "        [-1.37565812e-02-3.91905175e-02j, -1.33534149e-02-4.73701169e-02j, -4.80654734e-02-5.40799402e-02j, -4.44972926e-03+1.22506191e-03j, -5.59473320e-04-5.56933999e-04j]]),\n",
       " 0)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5\n",
    "i, j = 2, 3\n",
    "npr.seed(0)\n",
    "a = npr.randn(N, N)\n",
    "d, r = myeig(a)\n",
    "l = np.linalg.inv(r)\n",
    "print(np.allclose(a, (r * d) @ l))\n",
    "print(np.allclose(r, myeig(a + ep * np.eye(1, 5, i).T * np.eye(1, 5, j))[1]))\n",
    "l @ ((myeig(a + ep * np.eye(1, 5, i).T * np.eye(1, 5, j))[1] - r) / ep), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        +0.j        ,  0.        -1.30060987j,  0.68571721-0.19545018j,  0.27758211+0.21533138j,  0.19769616-0.2209446j ],\n",
       "       [-0.        +1.30060987j,  0.        +0.j        ,  0.68571721+0.19545018j,  0.19769616+0.2209446j ,  0.27758211-0.21533138j],\n",
       "       [-0.68571721+0.19545018j, -0.68571721-0.19545018j,  0.        +0.j        ,  0.16848114+0.39842665j,  0.16848114-0.39842665j],\n",
       "       [-0.27758211-0.21533138j, -0.19769616-0.2209446j , -0.16848114-0.39842665j,  0.        +0.j        ,  0.        -0.23483581j],\n",
       "       [-0.19769616+0.2209446j , -0.27758211+0.21533138j, -0.16848114+0.39842665j, -0.        +0.23483581j,  0.        +0.j        ]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = 1 / (d - d[:, None] + np.diag(np.infty * np.ones(5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21316024+1.65607966e-01j,  0.76863769-1.36931603e+00j, -0.41321134-8.91555897e-01j, -0.36639891+1.12330187e+00j, -0.2466083 +7.64473545e-01j],\n",
       "       [ 0.21316024-1.65607966e-01j,  0.76863769+1.36931603e+00j, -0.41321134+8.91555897e-01j, -0.36639891-1.12330187e+00j, -0.2466083 -7.64473545e-01j],\n",
       "       [-0.46075964+2.39335188e-16j, -1.51491026+2.27531001e-16j,  0.54475547-9.24524371e-17j, -1.03250401+7.00104548e-17j,  0.40835738-6.13329824e-17j],\n",
       "       [ 0.78322958-1.20706658e-01j, -0.05916687+6.79858420e-01j,  0.11574507+2.43233497e-01j,  0.57440695+2.85078463e-01j,  0.04316516+4.68863293e-01j],\n",
       "       [ 0.78322958+1.20706658e-01j, -0.05916687-6.79858420e-01j,  0.11574507-2.43233497e-01j,  0.57440695-2.85078463e-01j,  0.04316516-4.68863293e-01j]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00-2.22044605e-16j,  0.00000000e+00+5.55111512e-17j, -1.11022302e-16+0.00000000e+00j, -5.55111512e-17+0.00000000e+00j, -2.22044605e-16-1.17961196e-16j],\n",
       "       [ 1.66533454e-16-2.22044605e-16j,  1.00000000e+00-1.11022302e-16j, -5.55111512e-17-1.11022302e-16j,  0.00000000e+00+0.00000000e+00j,  2.22044605e-16-5.55111512e-17j],\n",
       "       [-5.55111512e-17+6.93889390e-17j,  2.77555756e-17+1.66533454e-16j,  1.00000000e+00+9.14942329e-17j, -2.77555756e-17+0.00000000e+00j, -5.55111512e-17+2.22044605e-16j],\n",
       "       [ 4.16333634e-17-2.77555756e-17j,  1.38777878e-17-1.38777878e-16j, -1.04083409e-17+0.00000000e+00j,  1.00000000e+00+0.00000000e+00j,  0.00000000e+00-2.77555756e-17j],\n",
       "       [ 2.77555756e-17+2.77555756e-17j, -5.55111512e-17-8.32667268e-17j, -6.93889390e-18-5.55111512e-17j,  5.55111512e-17+0.00000000e+00j,  1.00000000e+00-1.38777878e-17j]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l @ r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
